{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe044949",
   "metadata": {},
   "source": [
    "## Data Transformation trial-runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5fcaa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db2bdf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\USER\\Desktop\\MLDefaults\\Heart-Attack-Prediction-Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f090c0b3",
   "metadata": {},
   "source": [
    "## Trial-runs for entity_config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6dbac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    selected_data_file: Path\n",
    "    processed_data_file: Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21214d53",
   "metadata": {},
   "source": [
    "## Trial-runs for configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb7dc415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all project paths and modules necessary for project configurations \n",
    "from heartAttack.constants import  *\n",
    "from heartAttack.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa09da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating the configuration file \n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH, \n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        selected_schema_filepath = SELECTED_SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.selected_schema = read_yaml(selected_schema_filepath)\n",
    "       \n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        data_processing_config = self.config.data_processing \n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            processed_data_file=Path(config.processed_data_file),\n",
    "            selected_data_file=data_processing_config.selected_data_file,\n",
    "        )\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a6fd31",
   "metadata": {},
   "source": [
    "## Trial-runs for data_transformation_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b97c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from pathlib import Path \n",
    "from heartAttack import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28d25aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "        self.df = pd.read_csv(self.config.selected_data_file)\n",
    "        self.processed_df = None\n",
    "    \n",
    "\n",
    "    def process_and_store_data(self) -> None:\n",
    "        \"\"\"\n",
    "        Execute full processing pipeline and store results\n",
    "        Args:\n",
    "            df: Raw input DataFrame\n",
    "        \"\"\"\n",
    "        df=self.df.copy() #work on a copy of dataframe\n",
    "        df = self.fill_missing_with_mode(df)  # Step 2: Handle missing values: Example to all call classes tranforming data here\n",
    "        self.processed_df = df # Store processed data\n",
    "        \n",
    "        # Save to artifacts\n",
    "        os.makedirs(self.config.root_dir, exist_ok=True)\n",
    "        save_path = Path(self.config.root_dir) / \"processed_df.csv\"\n",
    "        df.to_csv(save_path, index=False)\n",
    "        logger.info(f\"Processed data stored at: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c3249",
   "metadata": {},
   "source": [
    "## Trial-runs for data_transformation_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ee62a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.process_and_store_data()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raisingVillage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
